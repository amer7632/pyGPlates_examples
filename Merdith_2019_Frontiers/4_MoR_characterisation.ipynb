{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first main step of our methodology. Here we have a pre-existing file (PlateBoundaryTypes) which is a summary of the plate boundaries in the plate model (e.g. lat/lon of start/end points for each segment of a ridge/trench/fault, divergence speed, length, obliquity etc.). We use that data, alongside estimates in the literature of crustal thickness, subdivision of crustal lithologies (e.g. upper/lower volcanics, dykes, gabbros etc.), a parameterisation of serpentinisation etc. to the build the model for carbon storage and serpentinite in ocean crust at ridges, at each time step. In order to properly sample all the parameter space, we do each calcualtion 10000 times per ridge segment. We then save the mean of these values into a big dictionary, which we will access in the next notebook as we start rotating the points through time. We take just the mean because we have the full distribution already saved (3_Uncertainty_Distributions_per_spreading_rate.ipnyb), and we will use that distribution to perturb our result at a trench.\n",
    "\n",
    "In the corresponding paper (Merdith et al. 2019) we wanted to explore the uncertainy inherent in spreading rate for ocean basins that have no recorded spreading history (i.e. prior to the Jurassic mostly). We differentiated our two approahces as (i) plate model spreading rate (PMSR) and (ii) Pacific Ocean spreading rate (POSR).\n",
    "\n",
    "(i) uses the spreading rate in the plate model as it as been constructed \n",
    "(ii) we assume that the spreading rate for the Pacific Ocean since 83 Ma is representative of 'external' oceans (ie. oceans without continental lithosphere and fully ringed by subduction). We built a distribution of expected Pacific Ocean spreading rates (see Notebook 1_Spreading_rate_distributions.ipynb) and instead of using the spreading rate for external oceans in times prior to the Jurassic, we randomly select a spreading rate from that distribution.  As is, these lines are currently blocked out in the below code.\n",
    "\n",
    "References\n",
    "\n",
    "Merdith, A.S., Atkins, S.E., and Tetley, M.G. (2019). Tectonic controls on carbon and serpentinite storage in subducted upper oceanic lithosphere for the past 320 Ma. Frontiers: Earth Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import MOR_crust_calculation\n",
    "import pickle\n",
    "from scipy import interpolate\n",
    "from collections import defaultdict\n",
    "import MOR_characterisation_serp_flux_FINAL\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select random pacific spreading rate\n",
    "def random_spreading(samples,distribution):\n",
    "    y = np.random.randint(1001,size=samples)\n",
    "    return distribution[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crust_characterisation(start, stop, step, df):\n",
    "\n",
    "    '''\n",
    "    Characterises the crust at each time step using a plate model.\n",
    "    '''\n",
    "    C_storage = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Set up time array\n",
    "    min_time = start\n",
    "    max_time = stop\n",
    "    time_step = step\n",
    "    times = np.arange(min_time,max_time + time_step,time_step)\n",
    "\n",
    "    # deviation angle (in degrees) to split transforms vs. ridges from\n",
    "    deviation_angle= 70\n",
    "    #time resolution to extract data\n",
    "    time_resolution = 1\n",
    "    SR = 'Spreading Rate'\n",
    "    prop_per = 'Peridotite'\n",
    "    DS = 'Degree of Serpentinisation'\n",
    "    CO2wt_mean = 'CO2 mean'\n",
    "    CO2wt_std = 'CO2 std'\n",
    "    thick_mean = 'Thickness Mean'\n",
    "    thick_std = 'Thickness std'\n",
    "    vertical_area_mean = 'Vertical Area Mean'\n",
    "    vertical_area_std = 'Vertical Area std'\n",
    "    C_total = 'C-prod'\n",
    "    C_total_vertical = 'C-prod_vertical'\n",
    "    C_volcanic_serp = 'C-Volcanic_serp'\n",
    "    serpentinites_thick = 'Serpentinites_raw'\n",
    "    serpentinites_vertical = 'Serpentinites_raw_vertical'\n",
    "    PDF_params = 'PDF Parameters'\n",
    "    length = 'Boundary-Length'\n",
    "    boundary = 'Boundary-Type'\n",
    "    StartLat = 'Start-Lat-Point'\n",
    "    StartLon = 'Start-Lon-Point'\n",
    "    EndLat = 'End-Lat-Point'\n",
    "    EndLon = 'End-Lon-Point'\n",
    "    RightPlateID = 'RightPlate'\n",
    "    LeftPlateID = 'LeftPlate'\n",
    "    Index = 'Index'\n",
    "\n",
    "    panthalassa_plate_ids = ['902',\n",
    "                                       '919',\n",
    "                                       '926']\n",
    "\n",
    "    #inititate loop to extract data\n",
    "    for time in times:\n",
    "        print time,  'Ma'\n",
    "        #we only need to cut up spreading ridges by velocity\n",
    "        subset1 = df[(df['Time_Ma']>=time)\n",
    "                  & (df['Time_Ma']<(time+time_resolution))\n",
    "                  & (df['FeatureType']=='gpml:MidOceanRidge')\n",
    "                  & (np.abs(df['Deviation_mod_deg'])<=deviation_angle)]\n",
    "        #print len(subset1)\n",
    "\n",
    "        #create temporary storage for values\n",
    "        C_storage[time][SR] = []\n",
    "        C_storage[time][prop_per] = []\n",
    "        C_storage[time][DS] = []\n",
    "        C_storage[time][CO2wt_mean] = []\n",
    "        C_storage[time][CO2wt_std] = []\n",
    "        C_storage[time][thick_mean] = []\n",
    "        C_storage[time][thick_std] = []\n",
    "        C_storage[time][vertical_area_mean] = []\n",
    "        C_storage[time][vertical_area_std] = []\n",
    "        C_storage[time][serpentinites_thick] = []\n",
    "        C_storage[time][serpentinites_vertical] = []\n",
    "        C_storage[time][C_volcanic_serp] = []\n",
    "        C_storage[time][C_total] = []\n",
    "        C_storage[time][C_total_vertical] = []\n",
    "        C_storage[time][PDF_params] = []\n",
    "        C_storage[time][length] = []\n",
    "        C_storage[time][boundary] = []\n",
    "        C_storage[time][StartLat] = []\n",
    "        C_storage[time][StartLon] = []\n",
    "        C_storage[time][EndLat] = []\n",
    "        C_storage[time][EndLon] = []\n",
    "        C_storage[time][RightPlateID] = []\n",
    "        C_storage[time][LeftPlateID] = []\n",
    "        C_storage[time][Index] = []\n",
    "\n",
    "        for index, row in subset1.iterrows():\n",
    "\n",
    "\n",
    "           #returns full spreading rate/velocity in cm/year, times by 10 to convert to km/Ma\n",
    "            velocity = np.ones(samples)\n",
    "            velocity = velocity*row.Plate_Velocity*10\n",
    "\n",
    "            #block out if not using plate model\n",
    "            #for POSR\n",
    "            #if time > 180:\n",
    "            #    new_conjugate_plates = (row.RightPlate,row.LeftPlate)\n",
    "            #    if all(x in panthalassa_plate_ids for x in new_conjugate_plates) == True:\n",
    "            #        velocity = np.ones(samples)\n",
    "            #        velocity = velocity*random_spreading(samples,spread_dist)*10\n",
    "            #        #print 'here', velocity\n",
    "\n",
    "            #calculate the mean bottom water temperature for the first 20 Ma existence of a parcel of ocean crust\n",
    "            temp_tmp = []\n",
    "            bottom_water_temperature = np.ones(samples)\n",
    "            for i in np.arange(time,time-21,-1):\n",
    "                if i < 0:\n",
    "                    break\n",
    "                temp_tmp.append(bottom_water_temperature_curve[i])\n",
    "            bottom_water_temperature = bottom_water_temperature * np.mean(temp_tmp)\n",
    "\n",
    "            per = MOR_characterisation_serp_flux_FINAL.SR_and_peridotite(samples,\n",
    "                                                                         velocity)\n",
    "\n",
    "            volcanic_percent = 100 - per\n",
    "            asymmetry_factor = 1\n",
    "            calc_length = row.Length_km\n",
    "\n",
    "            #calculate variables for mid ocean ridge segments\n",
    "\n",
    "            calc_length = row.Length_km\n",
    "            width = velocity\n",
    "            #as all velocitie are the same for each point, we just check the first\n",
    "            if velocity[0] <= 40:\n",
    "                asymmetry_factor = 1\n",
    "                thickness = MOR_characterisation_serp_flux_FINAL.SR_and_thickness_slow_ultraslow(samples)\n",
    "\n",
    "                tmp_DS = MOR_characterisation_serp_flux_FINAL.SR_and_dsSurf_slow_ultraslow(samples,\n",
    "                                                                                           velocity,\n",
    "                                                                                          thickness) #DS and thickness is called within this function\n",
    "                #print DS\n",
    "                carbon_max, CO2_gabbro = MOR_characterisation_serp_flux_FINAL.carbon_content_slow_ultraslow(samples,\n",
    "                                                                                                            velocity)\n",
    "                upper_volc_CO2 = lower_volc_CO2 = transition_CO2 = sheeted_dykes_CO2 = 0\n",
    "                upper_volc_thickness = lower_volc_thickness = transition_thickness = sheeted_dykes_thickness = 0\n",
    "                gabbros_thickness = thickness * volcanic_percent/100\n",
    "\n",
    "                #incase a neg CO2 value comes back (i think this was fixed in previous tweaks, but\n",
    "                #leaving it in to be sure)\n",
    "                indices_neg_CO2_gabbro = CO2_gabbro < 0\n",
    "                CO2_gabbro[indices_neg_CO2_gabbro] = 0\n",
    "                CO2_volcanic = gabbros_thickness * CO2_gabbro\n",
    "\n",
    "            else:\n",
    "                carbon_max = 0\n",
    "                tmp_DS = MOR_characterisation_serp_flux_FINAL.SR_and_dsSurf_inter_fast(samples,\n",
    "                                                                                   velocity) #DS and thickness is called within this function\n",
    "\n",
    "                thickness, upper_volc_thickness, lower_volc_thickness, transition_thickness, \\\n",
    "                sheeted_dykes_thickness, gabbros_thickness \\\n",
    "                = MOR_characterisation_serp_flux_FINAL.SR_and_thickness_inter_fast(samples,tmp_DS,volcanic_percent)\n",
    "\n",
    "                upper_volc_CO2, lower_volc_CO2, transition_CO2, sheeted_dykes_CO2, \\\n",
    "                CO2_gabbro, bottom_water_temperature_multiplier = MOR_characterisation_serp_flux_FINAL.carbon_content_inter_fast(samples,\n",
    "                                                                                            velocity,\n",
    "                                                                                            bottom_water_temperature)\n",
    "                #incase a neg CO2 value comes back (i think this was fixed in previous tweaks, but\n",
    "                #leaving it in to be sure)\n",
    "                indices_neg_CO2_gabbro = CO2_gabbro < 0\n",
    "                CO2_gabbro[indices_neg_CO2_gabbro] = 0\n",
    "\n",
    "                #gives us total CO2 storage in volcanics as a fraction (NOT A PERCENT)\n",
    "                CO2_volcanic =  (upper_volc_thickness * upper_volc_CO2 + \\\n",
    "                    lower_volc_thickness * lower_volc_CO2 + \\\n",
    "                    transition_thickness * transition_CO2 + \\\n",
    "                    sheeted_dykes_thickness * sheeted_dykes_CO2 + \\\n",
    "                    gabbros_thickness * CO2_gabbro)/(thickness * volcanic_percent/100)\n",
    "\n",
    "                #incase a neg CO2 value comes back (i think this was fixed in previous tweaks, but\n",
    "                #leaving it in to be sure)\n",
    "                indices_neg_CO2_volcanic = CO2_volcanic < 0\n",
    "                CO2_volcanic[indices_neg_CO2_volcanic] = 0\n",
    "\n",
    "\n",
    "            #carbon in serpentinite\n",
    "            max_DS = 100\n",
    "            #print tmp_DS\n",
    "            if velocity[0] > 40:\n",
    "                 #for fast ridges just assume max C is .32? questionable, no data available i think\n",
    "                carbon_max = .32\n",
    "            m = carbon_max/max_DS\n",
    "            \n",
    "            #bring it all together\n",
    "            C_thickness_volcanics = thickness * volcanic_percent * 1/100 * CO2_volcanic * 1/100 * 12./44.\n",
    "            C_thickness_serpentinites = thickness * per * 1/100 * 1000.0/865.0 * tmp_DS * m *1/100 * 12./44.\n",
    "            C_total_volc_serp =  C_thickness_volcanics + C_thickness_serpentinites\n",
    "\n",
    "            peridotites_point_thickness = thickness * per * 1/100\n",
    "            serpentinites_point_thickness = peridotites_point_thickness * 1000.0/865.0 * tmp_DS *1/100\n",
    "\n",
    "            #print PDF_parameters\n",
    "            C_storage[time][SR].append(np.mean(velocity))\n",
    "            C_storage[time][prop_per].append(np.mean(per))\n",
    "            C_storage[time][DS].append(np.mean(tmp_DS))\n",
    "            C_storage[time][CO2wt_mean].append((np.mean(upper_volc_CO2),\n",
    "                                                 np.mean(lower_volc_CO2),\n",
    "                                                 np.mean(transition_CO2),\n",
    "                                                 np.mean(sheeted_dykes_CO2),\n",
    "                                                 np.mean(CO2_gabbro)))\n",
    "            C_storage[time][thick_mean].append((np.mean(thickness),\n",
    "                                                np.mean(upper_volc_thickness),\n",
    "                                                np.mean(lower_volc_thickness),\n",
    "                                                np.mean(transition_thickness),\n",
    "                                                np.mean(sheeted_dykes_thickness),\n",
    "                                                np.mean(gabbros_thickness),\n",
    "                                                np.mean(peridotites_point_thickness)))\n",
    "            C_storage[time][vertical_area_mean].append((np.mean(upper_volc_thickness * velocity),\n",
    "                                                        np.mean(lower_volc_thickness * velocity),\n",
    "                                                        np.mean(transition_thickness * velocity),\n",
    "                                                        np.mean(sheeted_dykes_thickness * velocity),\n",
    "                                                        np.mean(gabbros_thickness * velocity),\n",
    "                                                        np.mean(peridotites_point_thickness * velocity)))\n",
    "            #multiply by mass C/mass CO2 to get C\n",
    "            C_storage[time][C_total].append(np.mean(C_total_volc_serp))\n",
    "\n",
    "            C_storage[time][C_total_vertical].append(np.mean(C_total_volc_serp)*velocity)\n",
    "\n",
    "            C_storage[time][C_volcanic_serp].append((np.mean(C_thickness_volcanics),\n",
    "                                                     np.mean(CO2_volcanic * 12./44.),\n",
    "                                                     np.mean(C_thickness_serpentinites),\n",
    "                                                     np.mean(tmp_DS * m)))\n",
    "\n",
    "            C_storage[time][serpentinites_thick].append(np.mean(serpentinites_point_thickness))\n",
    "\n",
    "            C_storage[time][serpentinites_vertical].append(np.mean(serpentinites_point_thickness) * velocity)\n",
    "\n",
    "            C_storage[time][Index].append(index)\n",
    "            C_storage[time][length].append(row.Length_km)\n",
    "            C_storage[time][boundary].append(row.FeatureType)\n",
    "            C_storage[time][StartLat].append(row.StartPointLat)\n",
    "            C_storage[time][StartLon].append(row.StartPointLon)\n",
    "            C_storage[time][EndLat].append(row.EndPointLat)\n",
    "            C_storage[time][EndLon].append(row.EndPointLon)\n",
    "            C_storage[time][RightPlateID].append(row.RightPlate)\n",
    "            C_storage[time][LeftPlateID].append(row.LeftPlate)\n",
    "\n",
    "\n",
    "    #save if wanted\n",
    "\n",
    "    date = datetime.today().strftime('%Y-%m-%d')\n",
    "    filename = 'C_storage_%s_plate_model_velocity.p' % date\n",
    "    outfile = open('%s/%s' % (datadir, filename), 'wb')\n",
    "    pickle.dump(C_storage, outfile)\n",
    "    outfile.close()\n",
    "\n",
    "    return(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/Andrew/Documents/PhD/Scripts/Python_Scripts/pyGPlates_examples/Merdith_2019_Frontiers/Sample_Data/'\n",
    "savedir = '/Users/Andrew/Documents/PhD/Scripts/Python_Scripts/pyGPlates_examples/Merdith_2019_Frontiers/output/'\n",
    "\n",
    "#NB in cm/a\n",
    "spread_dist = pickle.load(open('%sDistribution_for_random_spreading_Pacific100My.p.py' % datadir,'rb'))\n",
    "\n",
    "# import previously made file in 'extract velocities'\n",
    "file = '%sPlateBoundaryTypes_400-0_25Oct19.h5' % datadir\n",
    "df = pd.read_hdf(file,'Statistics_table')\n",
    "tags = df['FeatureType']\n",
    "\n",
    "resolution = 1\n",
    "samples=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bottom water data\n",
    "bottom_water_DF = pd.read_csv('%s/Bottom_water_temp_Muller_et_al.csv' % datadir)\n",
    "#turn into arrays\n",
    "x = np.asarray(bottom_water_DF['Age'])\n",
    "y = np.asarray(bottom_water_DF['Temp'])\n",
    "#flip arrays so they are going back in time\n",
    "x = x[::-1]\n",
    "y = y[::-1]\n",
    "#interpolate into linear 1 Ma intervals\n",
    "f = interpolate.interp1d(x, y)\n",
    "x_new = np.linspace(0,400,401)\n",
    "bottom_water_temperature_curve = f(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ma\n",
      "1 Ma\n",
      "2 Ma\n",
      "3 Ma\n",
      "4 Ma\n",
      "5 Ma\n",
      "6 Ma\n",
      "7 Ma\n",
      "8 Ma\n",
      "9 Ma\n",
      "10 Ma\n",
      "11 Ma\n",
      "12 Ma\n",
      "13 Ma\n",
      "14 Ma\n",
      "15 Ma\n",
      "16 Ma\n",
      "17 Ma\n",
      "18 Ma\n",
      "19 Ma\n",
      "20 Ma\n",
      "21 Ma\n",
      "22 Ma\n",
      "23 Ma\n",
      "24 Ma\n",
      "25 Ma\n",
      "26 Ma\n",
      "27 Ma\n",
      "28 Ma\n",
      "29 Ma\n",
      "30 Ma\n",
      "31 Ma\n",
      "32 Ma\n",
      "33 Ma\n",
      "34 Ma\n",
      "35 Ma\n",
      "36 Ma\n",
      "37 Ma\n",
      "38 Ma\n",
      "39 Ma\n",
      "40 Ma\n",
      "41 Ma\n",
      "42 Ma\n",
      "43 Ma\n",
      "44 Ma\n",
      "45 Ma\n",
      "46 Ma\n",
      "47 Ma\n",
      "48 Ma\n",
      "49 Ma\n",
      "50 Ma\n",
      "51 Ma\n",
      "52 Ma\n",
      "53 Ma\n",
      "54 Ma\n",
      "55 Ma\n",
      "56 Ma\n",
      "57 Ma\n",
      "58 Ma\n",
      "59 Ma\n",
      "60 Ma\n",
      "61 Ma\n",
      "62 Ma\n",
      "63 Ma\n",
      "64 Ma\n",
      "65 Ma\n",
      "66 Ma\n",
      "67 Ma\n",
      "68 Ma\n",
      "69 Ma\n",
      "70 Ma\n",
      "71 Ma\n",
      "72 Ma\n",
      "73 Ma\n",
      "74 Ma\n",
      "75 Ma\n",
      "76 Ma\n",
      "77 Ma\n",
      "78 Ma\n",
      "79 Ma\n",
      "80 Ma\n",
      "81 Ma\n",
      "82 Ma\n",
      "83 Ma\n",
      "84 Ma\n",
      "85 Ma\n",
      "86 Ma\n",
      "87 Ma\n",
      "88 Ma\n",
      "89 Ma\n",
      "90 Ma\n",
      "91 Ma\n",
      "92 Ma\n",
      "93 Ma\n",
      "94 Ma\n",
      "95 Ma\n",
      "96 Ma\n",
      "97 Ma\n",
      "98 Ma\n",
      "99 Ma\n",
      "100 Ma\n",
      "101 Ma\n",
      "102 Ma\n",
      "103 Ma\n",
      "104 Ma\n",
      "105 Ma\n",
      "106 Ma\n",
      "107 Ma\n",
      "108 Ma\n",
      "109 Ma\n",
      "110 Ma\n",
      "111 Ma\n",
      "112 Ma\n",
      "113 Ma\n",
      "114 Ma\n",
      "115 Ma\n",
      "116 Ma\n",
      "117 Ma\n",
      "118 Ma\n",
      "119 Ma\n",
      "120 Ma\n",
      "121 Ma\n",
      "122 Ma\n",
      "123 Ma\n",
      "124 Ma\n",
      "125 Ma\n",
      "126 Ma\n",
      "127 Ma\n",
      "128 Ma\n",
      "129 Ma\n",
      "130 Ma\n",
      "131 Ma\n",
      "132 Ma\n",
      "133 Ma\n",
      "134 Ma\n",
      "135 Ma\n",
      "136 Ma\n",
      "137 Ma\n",
      "138 Ma\n",
      "139 Ma\n",
      "140 Ma\n",
      "141 Ma\n",
      "142 Ma\n",
      "143 Ma\n",
      "144 Ma\n",
      "145 Ma\n",
      "146 Ma\n",
      "147 Ma\n",
      "148 Ma\n",
      "149 Ma\n",
      "150 Ma\n",
      "151 Ma\n",
      "152 Ma\n",
      "153 Ma\n",
      "154 Ma\n",
      "155 Ma\n",
      "156 Ma\n",
      "157 Ma\n",
      "158 Ma\n",
      "159 Ma\n",
      "160 Ma\n",
      "161 Ma\n",
      "162 Ma\n",
      "163 Ma\n",
      "164 Ma\n",
      "165 Ma\n",
      "166 Ma\n",
      "167 Ma\n",
      "168 Ma\n",
      "169 Ma\n",
      "170 Ma\n",
      "171 Ma\n",
      "172 Ma\n",
      "173 Ma\n",
      "174 Ma\n",
      "175 Ma\n",
      "176 Ma\n",
      "177 Ma\n",
      "178 Ma\n",
      "179 Ma\n",
      "180 Ma\n",
      "181 Ma\n",
      "182 Ma\n",
      "183 Ma\n",
      "184 Ma\n",
      "185 Ma\n",
      "186 Ma\n",
      "187 Ma\n",
      "188 Ma\n",
      "189 Ma\n",
      "190 Ma\n",
      "191 Ma\n",
      "192 Ma\n",
      "193 Ma\n",
      "194 Ma\n",
      "195 Ma\n",
      "196 Ma\n",
      "197 Ma\n",
      "198 Ma\n",
      "199 Ma\n",
      "200 Ma\n",
      "201 Ma\n",
      "202 Ma\n",
      "203 Ma\n",
      "204 Ma\n",
      "205 Ma\n",
      "206 Ma\n",
      "207 Ma\n",
      "208 Ma\n",
      "209 Ma\n",
      "210 Ma\n",
      "211 Ma\n",
      "212 Ma\n",
      "213 Ma\n",
      "214 Ma\n",
      "215 Ma\n",
      "216 Ma\n",
      "217 Ma\n",
      "218 Ma\n",
      "219 Ma\n",
      "220 Ma\n",
      "221 Ma\n",
      "222 Ma\n",
      "223 Ma\n",
      "224 Ma\n",
      "225 Ma\n",
      "226 Ma\n",
      "227 Ma\n",
      "228 Ma\n",
      "229 Ma\n",
      "230 Ma\n",
      "231 Ma\n",
      "232 Ma\n",
      "233 Ma\n",
      "234 Ma\n",
      "235 Ma\n",
      "236 Ma\n",
      "237 Ma\n",
      "238 Ma\n",
      "239 Ma\n",
      "240 Ma\n",
      "241 Ma\n",
      "242 Ma\n",
      "243 Ma\n",
      "244 Ma\n",
      "245 Ma\n",
      "246 Ma\n",
      "247 Ma\n",
      "248 Ma\n",
      "249 Ma\n",
      "250 Ma\n"
     ]
    }
   ],
   "source": [
    "filename = crust_characterisation(0, 250, 1, df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
