{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the next step of the methodology. We have, from the previous step, xyz files of lat/lon/z values (mean thicknesses, carbon content, age etc.). Here we take these xyz files and using GMT turn them into rasters. We apply a block median to organise the points a bit better, then use spherical interpolation to make the grid. We output them to a separate folder. These rasters then let us calcualte the amount of carbon/serpentinite/[z value] that intersects with subduction zones, a certain age of lithosphere at a given time (i.e. how much, and where is the serpentinite that is 50 Ma old at 70 Ma).\n",
    "\n",
    "I hungrily await the day for pyGMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygplates\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/Andrew/Documents/PhD/Scripts/Python_Scripts/pyGPlates_examples/Merdith_2019_Frontiers/Sample_Data/'\n",
    "datadir_results = '/Users/Andrew/Documents/PhD/Scripts/Python_Scripts/pyGPlates_examples/Merdith_2019_Frontiers/output/x_y_z_model/'\n",
    "savedir = '/Users/Andrew/Documents/PhD/Scripts/Python_Scripts/pyGPlates_examples/Merdith_2019_Frontiers/output/rasters/'\n",
    "\n",
    "rotfile = '%sMatthews_etal_GPC_2016_410-0Ma_GK07.rot' % datadir\n",
    "coastlines = '%sGlobal_EarthByte_GeeK07_COB_Terranes_Matthews_etal.gpml' % datadir\n",
    "\n",
    "rotation_model = pygplates.RotationModel(rotfile)\n",
    "#rotation_model_palaeozoic = pygplates.RotationModel(rotfile_palaeozoic)\n",
    "coastlines = pygplates.FeatureCollection(coastlines)\n",
    "polygons = []\n",
    "for feature in coastlines:\n",
    "    for geom in feature.get_geometries():\n",
    "        polygon = feature\n",
    "        polygon.set_geometry(pygplates.PolygonOnSphere(geom))\n",
    "        polygons.append(polygon)\n",
    "\n",
    "coastlines = pygplates.FeatureCollection(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmt_processing(time, parameters, savedir, COB_infile):\n",
    "\n",
    "    '''\n",
    "    uses GMT to make rasters at set times based on gridded interpolation of xyz points created\n",
    "    in previous notebook\n",
    "    '''\n",
    "    #loaddir_results = savedir\n",
    "    masked_COBs = '%smask_COB_%s.nc' % (datadir_results, time) #masking grids\n",
    "    infiles = [] #the results of the analysis we pass in\n",
    "    lst_of_bm_outfiles = [] #our blockmedian tmp files, deleted asap\n",
    "    lst_of_grids = [] #our regular gridded files using sphinterpolate\n",
    "    #outfiles_COB = [] #our final processed files after applying two masks (nn and COB)\n",
    "    outfiles_NN_COB = [] #our final processed files after applying two masks (nn and COB)\n",
    "    \n",
    "    #set some gmt parameters\n",
    "    region='-180./180./-90./90.'\n",
    "    resolution = '0.5'\n",
    "    \n",
    "    #we have a list of the parameters that are traced in each grid, so we populate each empty list with\n",
    "    #the appropriate file\n",
    "    for i in parameters:\n",
    "        infiles.append('%sPMSR_%s_%s_Ma' % (datadir_results, i,time))\n",
    "        lst_of_bm_outfiles.append('%sPMSR_%s_%s_Ma-bm_tmp' % (datadir_results, i,time))\n",
    "        lst_of_grids.append('%sPMSR_%s_%s_Ma.grd' % (savedir, i,time))\n",
    "        outfiles_NN_COB.append('%sPMSR_%s_%s_Ma_NN_COB_masked.grd' % (savedir, i,time))\n",
    "        #outfiles_COB.append('%sPMSR_%s_%s_Ma_COB_masked.grd' % (savedir, i,time))\n",
    "\n",
    "    #print outfiles    \n",
    "    #need to delete existing files for gmt to have an attempt\n",
    "    for ind, i in enumerate(lst_of_bm_outfiles):\n",
    "        if os.path.isfile(i[ind]):\n",
    "            os.remove(i)\n",
    "        if os.path.isfile(lst_of_bm_outfiles[ind]):\n",
    "            os.remove(lst_of_bm_outfiles[ind])\n",
    "        if os.path.isfile(outfiles_NN_COB[ind]):\n",
    "            os.remove(outfiles_NN_COB[ind])  \n",
    "        #if os.path.isfile(outfiles_COB[ind]):\n",
    "        #    os.remove(outfiles_COB[ind])  \n",
    "\n",
    "    #COB mask\n",
    "    os.system('gmt grdmask %s -R%s -I%s -N1/0/0 -V -G%s' % (COB_infile, region, resolution, masked_COBs))\n",
    "\n",
    "    for infile,bm_tmp in zip(infiles,lst_of_bm_outfiles):\n",
    "        os.system('gmt blockmedian %s -I%s -R%s -V > %s' % (infile, resolution, region, bm_tmp))\n",
    "    for bm_tmp,grid_outfile in zip(lst_of_bm_outfiles, lst_of_grids):\n",
    "        #print bm_tmp, grid_outfile\n",
    "        os.system('gmt sphinterpolate %s -G%s -I%s -R%s -V' % (bm_tmp, grid_outfile, resolution, region))\n",
    "  \n",
    "    #near neighbour mask\n",
    "    #they should all be the same, so we only need one filter\n",
    "    nn_outfile = '%sPMSR_Serp_%s_Ma_NN.grd' % (savedir,time) #make the grid\n",
    "    os.system('gmt nearneighbor %s -N4 -I%s -R%s -E0 -S3d -G%s' % (lst_of_bm_outfiles[0], resolution, region, nn_outfile))\n",
    "    nn_mask = '%sPMSR_Serp_%s_Ma_NN_mask.grd' % (savedir,time) #make the mask\n",
    "    os.system('gmt grdmath %s %s DIV = %s' % (nn_outfile, nn_outfile, nn_mask))\n",
    "    for grid,NN_COB_outfile in zip(lst_of_grids, outfiles_NN_COB):\n",
    "        os.system('gmt grdmath %s %s MUL %s MUL = %s' % (nn_mask, masked_COBs, grid, NN_COB_outfile))\n",
    "    #for grid,COB_outfile in zip(lst_of_grids, outfiles_COB):\n",
    "    #    os.system('gmt grdmath %s %s MUL = %s' % (masked_COBs, grid, COB_outfile))\n",
    "\n",
    "        #remove chunky files\n",
    "    for bm_tmp in lst_of_bm_outfiles:#, lst_of_grids):\n",
    "        #if os.path.isfile('%s' % grid):\n",
    "        #    os.remove('%s' % grid)\n",
    "        if os.path.isfile('%s' % bm_tmp):\n",
    "            os.remove('%s' % bm_tmp)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(0,201,1)\n",
    "#parameters = ['C', 'Serp', 'upper', 'SR']\n",
    "parameters = ['Serp', 'total', 'upper', 'lower', 'dykes', 'gabbro', 'SR', 'age']\n",
    "\n",
    "for time in times:\n",
    "    print time\n",
    "    pygplates.reconstruct(coastlines,\n",
    "                      rotation_model,\n",
    "                      '%sreconstructed_COB_%s.gmt' % (savedir, time),\n",
    "                      time)\n",
    "    COB_gmt = '%sreconstructed_COB_%s.gmt' % (savedir, time)\n",
    "        \n",
    "    gmt_processing(time, parameters, savedir, COB_gmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
